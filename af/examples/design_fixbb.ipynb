{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabDesign/blob/main/af/examples/design_fixbb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2k3sAYuiXe"
      },
      "source": [
        "#AfDesign (simple version for testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-AXy0s_4cKaK"
      },
      "outputs": [],
      "source": [
        "#@title install\n",
        "%%bash\n",
        "if [ ! -d af_backprop ]; then\n",
        "  git clone https://github.com/sokrypton/af_backprop.git\n",
        "  pip -q install biopython dm-haiku==0.0.5 ml-collections py3Dmol\n",
        "fi\n",
        "if [ ! -d params ]; then\n",
        "  mkdir params\n",
        "  curl -fsSL https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar | tar x -C params\n",
        "fi\n",
        "wget -qnc https://raw.githubusercontent.com/sokrypton/ColabFold/main/beta/colabfold.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%writefile design.py\n",
        "import random, copy\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.example_libraries.optimizers import sgd, adam\n",
        "\n",
        "def clear_mem():\n",
        "  backend = jax.lib.xla_bridge.get_backend()\n",
        "  for buf in backend.live_buffers(): buf.delete()\n",
        "\n",
        "from alphafold.common import protein\n",
        "from alphafold.data import pipeline, templates\n",
        "from alphafold.model import data, config, model, modules\n",
        "from alphafold.common import residue_constants\n",
        "\n",
        "from alphafold.model import all_atom\n",
        "from alphafold.model import folding\n",
        "\n",
        "# custom functions\n",
        "from utils import *\n",
        "import colabfold as cf\n",
        "\n",
        "import py3Dmol\n",
        "import matplotlib\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "class mk_design_model:\n",
        "  ######################################\n",
        "  # model initialization\n",
        "  ######################################\n",
        "  def __init__(self):\n",
        "\n",
        "    # decide if templates should be used    \n",
        "    self._default_opt = {\"temp\":1.0, \"soft\":0.0, \"hard\":0.0, \"dropout\":True, \"dropout_scale\":1.0, \"gumbel\":False}\n",
        "\n",
        "    # setup which model params to use\n",
        "    model_name = \"model_3_ptm\"\n",
        "    \n",
        "    cfg = config.model_config(model_name)\n",
        "\n",
        "    # enable checkpointing\n",
        "    cfg.model.global_config.use_remat = True\n",
        "\n",
        "    # subbatch_size / chunking\n",
        "    cfg.model.global_config.subbatch_size = None\n",
        "\n",
        "    # number of sequences\n",
        "    cfg.data.eval.max_msa_clusters = 1\n",
        "    cfg.data.common.max_extra_msa = 1\n",
        "    cfg.data.eval.masked_msa_replace_fraction = 0\n",
        "\n",
        "    # number of recycles\n",
        "    cfg.model.num_recycle = 0\n",
        "    cfg.data.common.num_recycle = 0\n",
        "\n",
        "    self._config = cfg\n",
        "\n",
        "    # setup model\n",
        "    self._model_params = [data.get_model_haiku_params(model_name=model_name, data_dir=\".\")]\n",
        "    self._runner = model.RunModel(self._config, self._model_params[0], is_training=True)\n",
        "\n",
        "    # load the other model_params\n",
        "    model_names = [\"model_1_ptm\",\"model_2_ptm\",\"model_4_ptm\",\"model_5_ptm\"]\n",
        "    for model_name in model_names:\n",
        "      params = data.get_model_haiku_params(model_name, '.')\n",
        "      self._model_params.append({k: params[k] for k in self._runner.params.keys()})\n",
        "\n",
        "    # define gradient function\n",
        "    self._grad_fn, self._fn = [jax.jit(x) for x in _get_fn(self)]\n",
        "\n",
        "    # define input function\n",
        "    self.prep_inputs = self._prep_fixbb\n",
        "  \n",
        "  ######################################\n",
        "  # input prep functions\n",
        "  ######################################\n",
        "\n",
        "  def _prep_features(self, length, template_features=None):\n",
        "    '''process features'''\n",
        "    num_seq = 1\n",
        "    sequence = \"A\" * length\n",
        "    feature_dict = {\n",
        "        **pipeline.make_sequence_features(sequence=sequence, description=\"none\", num_res=length),\n",
        "        **pipeline.make_msa_features(msas=[length*[sequence]], deletion_matrices=[num_seq*[[0]*length]])\n",
        "    }\n",
        "    if template_features is not None: feature_dict.update(template_features)    \n",
        "    inputs = self._runner.process_features(feature_dict, random_seed=0)\n",
        "    if num_seq > 1:\n",
        "      inputs[\"msa_row_mask\"] = jnp.ones_like(inputs[\"msa_row_mask\"])\n",
        "      inputs[\"msa_mask\"] = jnp.ones_like(inputs[\"msa_mask\"])\n",
        "    return inputs\n",
        "\n",
        "  def _prep_pdb(self, pdb_filename, chain=None):\n",
        "    '''extract features from pdb'''\n",
        "    if chain is None: chains = [None]\n",
        "    else: chains = chain.split(\",\")\n",
        "    o,last = [],0\n",
        "    for chain in chains:\n",
        "      protein_obj = protein.from_pdb_string(pdb_to_string(pdb_filename), chain_id=chain)\n",
        "      batch = {'aatype': protein_obj.aatype,\n",
        "              'all_atom_positions': protein_obj.atom_positions,\n",
        "              'all_atom_mask': protein_obj.atom_mask}\n",
        "\n",
        "      has_ca = batch[\"all_atom_mask\"][:,0] == 1\n",
        "      batch = jax.tree_map(lambda x:x[has_ca], batch)\n",
        "      batch.update(all_atom.atom37_to_frames(**batch))\n",
        "\n",
        "      template_features = {\"template_aatype\":jax.nn.one_hot(protein_obj.aatype[has_ca],22),\n",
        "                          \"template_all_atom_masks\":protein_obj.atom_mask[has_ca],\n",
        "                          \"template_all_atom_positions\":protein_obj.atom_positions[has_ca]}\n",
        "      \n",
        "      residue_index = protein_obj.residue_index[has_ca] + last\n",
        "      last = residue_index[-1] + 50\n",
        "      o.append({\"batch\":batch,\n",
        "                \"template_features\":template_features,\n",
        "                \"residue_index\": residue_index})\n",
        "    o = jax.tree_multimap(lambda *x:np.concatenate(x,0),*o)\n",
        "    o[\"template_features\"] = {\"template_domain_names\":np.asarray([\"None\"]),\n",
        "                              **jax.tree_map(lambda x:x[None],o[\"template_features\"])}\n",
        "    return o                          \n",
        "\n",
        "  def _prep_fixbb(self, pdb_filename, chain=None, **kwargs):\n",
        "    '''prep inputs for fixed backbone design'''\n",
        "    pdb = self._prep_pdb(pdb_filename, chain=chain)\n",
        "    self._batch = pdb[\"batch\"]\n",
        "    self._wt_aatype = self._batch[\"aatype\"]\n",
        "    self._len = pdb[\"residue_index\"].shape[0]\n",
        "    self._inputs = self._prep_features(self._len, pdb[\"template_features\"])    \n",
        "    # set weights\n",
        "    self._default_weights = {\"dgram_cce\":1.0, \"fape\":0.0, \"rmsd\":0.0}\n",
        "    self._inputs[\"residue_index\"] = pdb[\"residue_index\"][None]\n",
        "    self.restart(**kwargs)\n",
        "\n",
        "  #################################\n",
        "  # initialization/restart function\n",
        "  #################################\n",
        "  def _setup_optimizer(self, optimizer=\"sgd\", lr_scale=1.0, **kwargs):\n",
        "    '''setup which optimizer to use'''\n",
        "    if optimizer == \"adam\":\n",
        "      optimizer = adam\n",
        "      lr = 0.02 * lr_scale\n",
        "    else:\n",
        "      optimizer = sgd\n",
        "      lr = 0.1 * lr_scale\n",
        "    self._init_fun, self._update_fun, self._get_params = optimizer(lr, **kwargs)\n",
        "    self._k = 0\n",
        "\n",
        "  def _init_seq(self, x=None):\n",
        "    '''initialize sequence'''\n",
        "    self._key, _key = jax.random.split(self._key)\n",
        "    shape = (1, self._len, 20)\n",
        "    if isinstance(x, np.ndarray) or isinstance(x, jnp.ndarray):\n",
        "      y = jnp.broadcast_to(x, shape)\n",
        "    elif isinstance(x, str):\n",
        "      if len(x) == self._len:\n",
        "        y = jax.nn.one_hot(jnp.array([residue_constants.restype_order.get(aa,-1) for aa in x]),20)\n",
        "        y = jnp.broadcast_to(2 * y, shape)\n",
        "      else:\n",
        "        if \"wt\" in x or \"wildtype\" in x:\n",
        "          y = jax.nn.one_hot(self._wt_aatype,20)\n",
        "          y = jnp.broadcast_to(2 * y, shape)\n",
        "        if \"gumbel\" in x: y = jax.random.gumbel(_key, shape)/2\n",
        "        if \"zeros\" in x: y = jnp.zeros(shape)\n",
        "        if \"soft\" in x: y = jax.nn.softmax(2 * y)\n",
        "    else:\n",
        "      y = 0.01 * jax.random.normal(_key, shape)\n",
        "    self._params = {\"seq\":y}\n",
        "    self._state = self._init_fun(self._params)\n",
        "\n",
        "  def restart(self, weights=None, seed=None, seq_init=\"soft_gumbel\", **kwargs):    \n",
        "    \n",
        "    # set weights and options\n",
        "    self.opt = {\"weights\":self._default_weights.copy()}\n",
        "    if weights is not None: self.opt[\"weights\"].update(weights)\n",
        "    self.opt.update(copy.deepcopy(self._default_opt))\n",
        "\n",
        "    # setup optimizer\n",
        "    self._setup_optimizer(**kwargs)    \n",
        "    \n",
        "    # initialize sequence\n",
        "    self._seed = random.randint(0,2147483647) if seed is None else seed\n",
        "    self._key = jax.random.PRNGKey(self._seed)\n",
        "    self._init_seq(seq_init)\n",
        "\n",
        "    # initialize trajectory\n",
        "    self.losses,self._traj = [],{\"xyz\":[],\"seq\":[],\"plddt\":[],\"pae\":[]}\n",
        "    self._best_loss, self._best_outs = np.inf, None\n",
        "\n",
        "  ######################################\n",
        "  # STEP FUNCTION\n",
        "  ######################################\n",
        "  def _step(self, weights=None, lr_scale=1.0, **kwargs):\n",
        "    '''do one step'''\n",
        "\n",
        "    if weights is not None: self.opt[\"weights\"].update(weights)\n",
        "    \n",
        "    # get current params\n",
        "    self._params = self._get_params(self._state)\n",
        "\n",
        "    # decide which model params to use\n",
        "    self._key, *keys = jax.random.split(self._key, 3)\n",
        "    self._model_num = int(jax.random.choice(keys[0],jnp.arange(5),[],replace=False))\n",
        "    \n",
        "    # update loss/outs/gradient\n",
        "    (self._loss, self._outs), self._grad = self._grad_fn(self._params, self._model_params[self._model_num],\n",
        "                                                        self._inputs, keys[1], self.opt)\n",
        "    self._losses = self._outs[\"losses\"] \n",
        "\n",
        "    # normalize gradient\n",
        "    g = self._grad[\"seq\"]\n",
        "    gn = jnp.linalg.norm(g,axis=(-1,-2),keepdims=True)\n",
        "    self._grad[\"seq\"] *= lr_scale * jnp.sqrt(self._len)/(gn+1e-7)\n",
        "\n",
        "    # apply gradient\n",
        "    self._state = self._update_fun(self._k, self._grad, self._state)\n",
        "    self._k += 1\n",
        "    _save_results(self, **kwargs)\n",
        "\n",
        "\n",
        "  ##############################################################################\n",
        "  # DESIGN FUNCTIONS\n",
        "  ##############################################################################\n",
        "  def design(self, iters,\n",
        "              temp=1.0, e_temp=None,\n",
        "              soft=False, e_soft=None,\n",
        "              hard=False, dropout=True, gumbel=False, **kwargs):\n",
        "    self.opt.update({\"hard\":1.0 if hard else 0.0,\"dropout\":dropout,\"gumbel\":gumbel})\n",
        "    if e_soft is None: e_soft = soft\n",
        "    if e_temp is None: e_temp = temp\n",
        "    for i in range(iters):\n",
        "      self.opt[\"temp\"] = e_temp + (temp - e_temp) * (1-i/(iters-1)) ** 2\n",
        "      self.opt[\"soft\"] = soft + (e_soft - soft) * i/(iters-1)\n",
        "      # decay learning rate based on temperature\n",
        "      lr_scale = (1 - self.opt[\"soft\"]) + (self.opt[\"soft\"] * self.opt[\"temp\"])\n",
        "      self._step(lr_scale=lr_scale, **kwargs)\n",
        "\n",
        "  def design_logits(self, iters, **kwargs):\n",
        "    '''optimize logits'''\n",
        "    self.design(iters, **kwargs)\n",
        "\n",
        "  def design_soft(self, iters, **kwargs):\n",
        "    ''' optimize softmax(logits/temp)'''\n",
        "    self.design(iters, soft=True, **kwargs)\n",
        "  \n",
        "  def design_hard(self, iters, **kwargs):\n",
        "    ''' optimize argmax(logits)'''\n",
        "    self.design(iters, soft=True, hard=True, **kwargs)\n",
        "\n",
        "  def design_2stage(self, soft_iters=100, temp_iters=100, hard_iters=50,\n",
        "                    temp=1.0, dropout=True, gumbel=False, **kwargs):\n",
        "    '''two stage design (soft→hard)'''\n",
        "    self.design(soft_iters, soft=True, temp=temp, dropout=dropout, gumbel=gumbel, **kwargs)\n",
        "    self.design(temp_iters, soft=True, temp=temp, dropout=dropout, gumbel=False,  e_temp=1e-2, **kwargs)\n",
        "    self.design(hard_iters, soft=True, temp=1e-2, dropout=False,   gumbel=False,  hard=True, save_best=True, **kwargs)\n",
        "\n",
        "  def design_3stage(self, soft_iters=300, temp_iters=100, hard_iters=50, \n",
        "                    temp=1.0, dropout=True, gumbel=False, **kwargs):\n",
        "    '''three stage design (logits→soft→hard)'''\n",
        "    self.design(soft_iters, e_soft=True, temp=temp, dropout=dropout, gumbel=gumbel, **kwargs)\n",
        "    self.design(temp_iters, soft=True,   temp=temp, dropout=dropout, gumbel=False, e_temp=1e-2,**kwargs)\n",
        "    self.design(hard_iters, soft=True,   temp=1e-2, dropout=False,   gumbel=False, hard=True, save_best=True, **kwargs)    \n",
        "  ######################################\n",
        "  # utils\n",
        "  ######################################\n",
        "  def get_seqs(self):\n",
        "    outs = self._outs if self._best_outs is None else self._best_outs\n",
        "    outs = jax.tree_map(lambda x:np.asarray(x), outs)\n",
        "    x = np.array(outs[\"seq\"]).argmax(-1)\n",
        "    return [\"\".join([order_restype[a] for a in s]) for s in x]\n",
        "  \n",
        "  def get_loss(self, x=\"loss\"):\n",
        "    '''output the loss (for entire trajectory)'''\n",
        "    return np.array([float(loss[x]) for loss in self.losses])\n",
        "\n",
        "  def save_pdb(self, filename=None):\n",
        "    '''save pdb coordinates'''\n",
        "    outs = self._outs if self._best_outs is None else self._best_outs\n",
        "    outs = jax.tree_map(lambda x:np.asarray(x), outs)\n",
        "    aatype = outs[\"seq\"].argmax(-1)[0]\n",
        "    p = {\"residue_index\":self._inputs[\"residue_index\"][0],\n",
        "          \"aatype\":aatype,\n",
        "          \"atom_positions\":outs[\"final_atom_positions\"],\n",
        "          \"atom_mask\":outs[\"final_atom_mask\"]}\n",
        "    b_factors = outs[\"plddt\"][:,None] * p[\"atom_mask\"]\n",
        "    p = protein.Protein(**p,b_factors=b_factors)\n",
        "    pdb_lines = protein.to_pdb(p)\n",
        "    if filename is None:\n",
        "      return pdb_lines\n",
        "    else:\n",
        "      with open(filename, 'w') as f: f.write(pdb_lines)\n",
        "  \n",
        "  ######################################\n",
        "  # plotting functions\n",
        "  ######################################\n",
        "  def animate(self, s=0, e=None, dpi=100):\n",
        "    sub_traj = {k:v[s:e] for k,v in self._traj.items()}\n",
        "    pos_ref = self._batch[\"all_atom_positions\"][:,1,:]\n",
        "    return make_animation(**sub_traj, pos_ref=pos_ref, length=None, dpi=dpi)\n",
        "    \n",
        "  def plot_pdb(self):\n",
        "    '''use py3Dmol to plot pdb coordinates'''\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    view.addModel(self.save_pdb(),'pdb')\n",
        "    view.setStyle({'cartoon': {}})\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                  {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
        "    view.zoomTo()\n",
        "    view.show()\n",
        "  \n",
        "  def plot_traj(self, dpi=100):\n",
        "    fig = plt.figure(figsize=(5,5), dpi=dpi)\n",
        "    gs = GridSpec(4,1, figure=fig)\n",
        "    ax1 = fig.add_subplot(gs[:3,:])\n",
        "    ax2 = fig.add_subplot(gs[3:,:])\n",
        "    ax1_ = ax1.twinx()\n",
        "    \n",
        "    rmsd = self.get_loss(\"rmsd\")\n",
        "    for k in [0.5,1,2,4,8,16,32]:\n",
        "      ax1.plot([0,len(rmsd)],[k,k],color=\"lightgrey\")\n",
        "    ax1.plot(rmsd,color=\"black\")\n",
        "    ax1_.plot(self.get_loss(\"seqid\"),color=\"green\",label=\"seqid\")\n",
        "    # axes labels\n",
        "    ax1.set_yscale(\"log\")\n",
        "    ticks = [0.25,0.5,1,2,4,8,16,32,64]\n",
        "    ax1.set(xticks=[])\n",
        "    ax1.set_yticks(ticks);ax1.set_yticklabels(ticks)\n",
        "    ax1.set_ylabel(\"RMSD\",color=\"black\");ax1_.set_ylabel(\"seqid\",color=\"green\")\n",
        "    ax1.set_ylim(0.25,64)\n",
        "    ax1_.set_ylim(0,0.4)\n",
        "    # extras\n",
        "    if \"soft\" in self.losses[0]:\n",
        "      ax2.plot(self.get_loss(\"soft\"),color=\"yellow\",label=\"soft\")\n",
        "    if \"temp\" in self.losses[0]:\n",
        "      ax2.plot(self.get_loss(\"temp\"),color=\"orange\",label=\"temp\")\n",
        "    if \"hard\" in self.losses[0]:\n",
        "      ax2.plot(self.get_loss(\"hard\"),color=\"red\",label=\"hard\")\n",
        "    ax2.set_ylim(-0.1,1.1)\n",
        "    ax2.set_xlabel(\"iterations\")\n",
        "    ax2.legend(loc='center left')\n",
        "    plt.show()\n",
        "\n",
        "######################################\n",
        "# SETUP LOSS FUNCTION\n",
        "######################################\n",
        "def _get_fn(self):\n",
        "\n",
        "  # setup function to get gradients\n",
        "  def mod(params, model_params, inputs, key, opt):\n",
        "\n",
        "    # initialize the loss function\n",
        "    losses = {}\n",
        "    w = opt[\"weights\"]\n",
        "\n",
        "    # set sequence\n",
        "    seq = params[\"seq\"] - params[\"seq\"].mean(-1,keepdims=True)\n",
        "\n",
        "    # straight-through/reparameterization\n",
        "    seq_logits = 2.0 * seq + jnp.where(opt[\"gumbel\"], jax.random.gumbel(key,seq.shape), 0.0)\n",
        "    seq_soft = jax.nn.softmax(seq_logits / opt[\"temp\"])\n",
        "    seq_hard = jax.nn.one_hot(seq_soft.argmax(-1), 20)\n",
        "    seq_hard = jax.lax.stop_gradient(seq_hard - seq_soft) + seq_soft\n",
        "\n",
        "    # create pseudo sequence\n",
        "    seq_pseudo = opt[\"soft\"] * seq_soft + (1-opt[\"soft\"]) * seq\n",
        "    seq_pseudo = opt[\"hard\"] * seq_hard + (1-opt[\"hard\"]) * seq_pseudo\n",
        "    \n",
        "    # save for aux output\n",
        "    aux = {\"seq\":seq_hard,\"seq_pseudo\":seq_pseudo}\n",
        "    \n",
        "    # update sequence\n",
        "    update_seq(seq_pseudo, inputs)\n",
        "    \n",
        "    # update amino acid sidechain identity\n",
        "    N,L = inputs[\"aatype\"].shape[:2]\n",
        "    aatype = jnp.broadcast_to(jax.nn.one_hot(seq_pseudo[0].argmax(-1),21),(N,L,21))\n",
        "    update_aatype(aatype, inputs)\n",
        "    \n",
        "    # scale dropout rate\n",
        "    inputs[\"scale_rate\"] = jnp.where(opt[\"dropout\"],jnp.full(1,opt[\"dropout_scale\"]),jnp.zeros(1))\n",
        "    \n",
        "    # get outputs\n",
        "    outputs = self._runner.apply(model_params, key, inputs)\n",
        "\n",
        "    fape_loss = get_fape_loss(self._batch, outputs, model_config=self._config)      \n",
        "    dgram_cce_loss = get_dgram_loss(self._batch, outputs, model_config=self._config)\n",
        "    rmsd_loss = get_rmsd_loss_w(self._batch, outputs)\n",
        "    losses.update({\"dgram_cce\":dgram_cce_loss, \"fape\":fape_loss, \"rmsd\":rmsd_loss})\n",
        "\n",
        "    # loss\n",
        "    loss = sum([v*w[k] if k in w else v*0 for k,v in losses.items()])\n",
        "\n",
        "    # save aux outputs\n",
        "    aux.update({\"final_atom_positions\":outputs[\"structure_module\"][\"final_atom_positions\"],\n",
        "                \"final_atom_mask\":outputs[\"structure_module\"][\"final_atom_mask\"],\n",
        "                \"plddt\":get_plddt(outputs),\n",
        "                \"losses\":losses})\n",
        "\n",
        "    return loss, (aux)\n",
        "  \n",
        "  return jax.value_and_grad(mod, has_aux=True, argnums=0), mod\n",
        "    \n",
        "def _save_results(self, save_best=False, verbose=True):\n",
        "  '''save the results and update trajectory'''\n",
        "\n",
        "  # save best result\n",
        "  if save_best and self._loss < self._best_loss:\n",
        "    self._best_loss = self._loss\n",
        "    self._best_outs = self._outs\n",
        "  \n",
        "  # compile losses\n",
        "  self._losses.update({\"model\":self._model_num,\"loss\":self._loss, \n",
        "                       **{k:self.opt[k] for k in [\"soft\",\"hard\",\"temp\"]}})\n",
        "  \n",
        "  # compute sequence recovery\n",
        "  _aatype = self._outs[\"seq\"].argmax(-1)\n",
        "  L = min(_aatype.shape[-1], self._wt_aatype.shape[-1])\n",
        "  seqid = (_aatype[...,:L] == self._wt_aatype[...,:L]).mean()\n",
        "  self._losses.update({\"seqid\":seqid})\n",
        "\n",
        "  # save losses\n",
        "  self.losses.append(self._losses)\n",
        "\n",
        "  # print losses      \n",
        "  if verbose:\n",
        "    I = [\"model\",\"recycles\"]\n",
        "    f = [\"soft\",\"temp\",\"seqid\"]\n",
        "    F = [\"loss\",\"dgram_cce\",\"fape\",\"rmsd\"]\n",
        "    I = \" \".join([f\"{x}: {self._losses[x]}\" for x in I if x in self._losses])\n",
        "    f = \" \".join([f\"{x}: {self._losses[x]:.2f}\" for x in f if x in self._losses])\n",
        "    F = \" \".join([f\"{x}: {self._losses[x]:.2f}\" for x in F if x in self._losses])\n",
        "    print(f\"{self._k}\\t{I} {f} {F}\")\n",
        "\n",
        "  # save trajectory\n",
        "  ca_xyz = self._outs[\"final_atom_positions\"][:,1,:]\n",
        "  traj = {\"xyz\":ca_xyz,\"plddt\":self._outs[\"plddt\"],\"seq\":self._outs[\"seq_pseudo\"]}\n",
        "  if \"pae\" in self._outs: traj.update({\"pae\":self._outs[\"pae\"]})\n",
        "  for k,v in traj.items(): self._traj[k].append(np.array(v))\n",
        "\n",
        "#####################################################################\n",
        "# UTILS\n",
        "#####################################################################\n",
        "def make_animation(xyz, seq, plddt=None, pae=None,\n",
        "                   pos_ref=None, line_w=2.0,\n",
        "                   dpi=100, interval=60, color_msa=\"Taylor\",\n",
        "                   length=None):\n",
        "\n",
        "  def align(P, Q, P_trim=None):\n",
        "    if P_trim is None: P_trim = P\n",
        "    p_trim = P_trim - P_trim.mean(0,keepdims=True)\n",
        "    p = P - P_trim.mean(0,keepdims=True)\n",
        "    q = Q - Q.mean(0,keepdims=True)\n",
        "    return p @ cf.kabsch(p_trim,q)\n",
        "\n",
        "  # compute reference position\n",
        "  if pos_ref is None: pos_ref = xyz[-1]\n",
        "  if length is None: length = len(pos_ref)\n",
        "  \n",
        "  # align to reference\n",
        "  pos_ref_trim = pos_ref[:length]\n",
        "  # align to reference position\n",
        "  new_positions = []\n",
        "  for i in range(len(xyz)):\n",
        "    new_positions.append(align(xyz[i],pos_ref_trim,xyz[i][:length]))\n",
        "  pos = np.asarray(new_positions)\n",
        "\n",
        "  # rotate for best view\n",
        "  pos_mean = np.concatenate(pos,0)\n",
        "  m = pos_mean.mean(0)\n",
        "  rot_mtx = cf.kabsch(pos_mean - m, pos_mean - m, return_v=True)\n",
        "  pos = (pos - m) @ rot_mtx + m\n",
        "  pos_ref_full = ((pos_ref - pos_ref_trim.mean(0)) - m) @ rot_mtx + m\n",
        "\n",
        "  # initialize figure\n",
        "  if pae is not None and len(pae) == 0: pae = None\n",
        "  fig = plt.figure()\n",
        "  gs = GridSpec(4,3, figure=fig)\n",
        "  if pae is not None:\n",
        "    ax1, ax2, ax3 = fig.add_subplot(gs[:3,:2]), fig.add_subplot(gs[3:,:]), fig.add_subplot(gs[:3,2:])\n",
        "  else:\n",
        "    ax1, ax2 = fig.add_subplot(gs[:3,:]), fig.add_subplot(gs[3:,:])\n",
        "\n",
        "  fig.subplots_adjust(top=0.95,bottom=0.1,right=0.95,left=0.05,hspace=0,wspace=0)\n",
        "  fig.set_figwidth(8); fig.set_figheight(6); fig.set_dpi(dpi)\n",
        "  ax2.set_xlabel(\"positions\"); ax2.set_yticks([])\n",
        "  if seq[0].shape[0] > 1: ax2.set_ylabel(\"sequences\")\n",
        "  else: ax2.set_ylabel(\"amino acids\")\n",
        "\n",
        "  ax1.set_title(\"N→C\") if plddt is None else ax1.set_title(\"pLDDT\")\n",
        "  if pae is not None:\n",
        "    ax3.set_title(\"pAE\")\n",
        "    ax3.set_xticks([])\n",
        "    ax3.set_yticks([])\n",
        "\n",
        "  # set bounderies\n",
        "  x_min,y_min,z_min = np.minimum(np.mean(pos.min(1),0),pos_ref_full.min(0)) - 5\n",
        "  x_max,y_max,z_max = np.maximum(np.mean(pos.max(1),0),pos_ref_full.max(0)) + 5\n",
        "\n",
        "  x_pad = ((y_max - y_min) * 2 - (x_max - x_min)) / 2\n",
        "  y_pad = ((x_max - x_min) / 2 - (y_max - y_min)) / 2\n",
        "  if x_pad > 0:\n",
        "    x_min -= x_pad\n",
        "    x_max += x_pad\n",
        "  else:\n",
        "    y_min -= y_pad\n",
        "    y_max += y_pad\n",
        "\n",
        "  ax1.set_xlim(x_min, x_max)\n",
        "  ax1.set_ylim(y_min, y_max)\n",
        "  ax1.set_xticks([])\n",
        "  ax1.set_yticks([])\n",
        "\n",
        "  # get animation frames\n",
        "  ims = []\n",
        "  for k in range(len(pos)):\n",
        "    ims.append([])\n",
        "    if plddt is None:\n",
        "      ims[-1].append(cf.plot_pseudo_3D(pos[k], ax=ax1, line_w=line_w, zmin=z_min, zmax=z_max))\n",
        "    else:\n",
        "      ims[-1].append(cf.plot_pseudo_3D(pos[k], c=plddt[k], cmin=0.5, cmax=0.9, ax=ax1, line_w=line_w, zmin=z_min, zmax=z_max))\n",
        "    if seq[k].shape[0] == 1:\n",
        "      ims[-1].append(ax2.imshow(seq[k][0].T, animated=True, cmap=\"bwr_r\",vmin=-1, vmax=1))\n",
        "    else:\n",
        "      cmap = matplotlib.colors.ListedColormap(jalview_color_list[color_msa])\n",
        "      vmax = len(jalview_color_list[color_msa]) - 1\n",
        "      ims[-1].append(ax2.imshow(seq[k].argmax(-1), animated=True, cmap=cmap, vmin=0, vmax=vmax, interpolation=\"none\"))\n",
        "    if pae is not None:\n",
        "      ims[-1].append(ax3.imshow(pae[k], animated=True, cmap=\"bwr\",vmin=0, vmax=30))\n",
        "\n",
        "  # make animation!\n",
        "  ani = animation.ArtistAnimation(fig, ims, blit=True, interval=interval)\n",
        "  plt.close()\n",
        "  return ani.to_html5_video()"
      ],
      "metadata": {
        "id": "r3vEJe3bCmYU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Vt7G_nbNeSQ3"
      },
      "outputs": [],
      "source": [
        "#@title import libraries\n",
        "import os\n",
        "os.environ['TF_CUDNN_DETERMINISTIC']='1'\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/af_backprop')\n",
        "\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from design import mk_design_model, clear_mem\n",
        "\n",
        "#########################\n",
        "def get_pdb(pdb_code=\"\"):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  else:\n",
        "    os.system(f\"wget -qnc https://files.rcsb.org/view/{pdb_code}.pdb\")\n",
        "    return f\"{pdb_code}.pdb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUfKrOzT0gOS"
      },
      "source": [
        "# fixed backbone design (fixbb)\n",
        "For a given protein backbone, generate/design a new sequence that AlphaFold thinks folds into that conformation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLd1DsnKzxBJ"
      },
      "outputs": [],
      "source": [
        "clear_mem()\n",
        "model = mk_design_model()\n",
        "model.prep_inputs(pdb_filename=get_pdb(\"1TEN\"), chain=\"A\")\n",
        "\n",
        "print(\"length\",  model._len)\n",
        "print(\"weights\", model.opt[\"weights\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.restart(seed=0)\n",
        "model.design_3stage()"
      ],
      "metadata": {
        "id": "u0AwskJ84NGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot_traj()  "
      ],
      "metadata": {
        "id": "8FB1v7dn1LL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW1KQiHKJpfp"
      },
      "outputs": [],
      "source": [
        "HTML(model.animate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEApO8YzBoS0"
      },
      "outputs": [],
      "source": [
        "model.plot_pdb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff3vjNFgBqc9"
      },
      "outputs": [],
      "source": [
        "model.save_pdb(f\"design.pdb\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_seqs()"
      ],
      "metadata": {
        "id": "nI7CdroMSZ_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CYgmkwIqSbFW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "q4qiU9I0QHSz"
      ],
      "name": "design_fixbb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
